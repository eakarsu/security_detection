version: '3.8'

# Use custom env file name
x-common-env: &common-env
  env_file: .env.security

services:
  # Database Services
  postgres:
    <<: *common-env
    image: postgres:16
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-nodeguard}
      POSTGRES_USER: ${POSTGRES_USER:-nodeguard}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/setup/init.sql:/docker-entrypoint-initdb.d/01-init.sql
      - ./scripts/setup/reset-db.sql:/docker-entrypoint-initdb.d/02-reset-db.sql
      - ./scripts/setup/seed_security_data.sql:/docker-entrypoint-initdb.d/03-seed-data.sql
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    networks:
      - security-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-nodeguard} -d ${POSTGRES_DB:-nodeguard}"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    <<: *common-env
    image: redis:7-alpine
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    command: redis-server --protected-mode no --bind 0.0.0.0 --maxmemory 256mb --maxmemory-policy allkeys-lru
    networks:
      - security-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  elasticsearch:
    <<: *common-env
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=${ELASTICSEARCH_PASSWORD}
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - cluster.name=security-detection
      - node.name=security-node-1
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "${ELASTICSEARCH_PORT:-9200}:9200"
    networks:
      - security-network
    healthcheck:
      test: ["CMD-SHELL", "curl -s -u elastic:${ELASTICSEARCH_PASSWORD} http://localhost:9200/_cluster/health | grep -q '\"status\":\"yellow\"\\|\"status\":\"green\"'"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Message Queue
  zookeeper:
    <<: *common-env
    image: confluentinc/cp-zookeeper:7.7.0
    restart: unless-stopped
    platform: linux/amd64
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_LOG4J_ROOT_LOGLEVEL: WARN
    ports:
      - "${ZOOKEEPER_PORT:-2181}:2181"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - security-network
    healthcheck:
      test: ["CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181"]
      interval: 30s
      timeout: 10s
      retries: 5

  kafka:
    <<: *common-env
    image: confluentinc/cp-kafka:7.7.0
    restart: unless-stopped
    platform: linux/amd64
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "${KAFKA_PORT:-9092}:9092"
      - "${KAFKA_JMX_PORT:-9101}:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:${KAFKA_PORT:-9092}
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - security-network
    healthcheck:
      test: ["CMD", "bash", "-c", "unset JMX_PORT; kafka-broker-api-versions --bootstrap-server localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Unified NodeGuard Security Platform
  # Single container with Frontend, Python API, and Node.js API
  nodeguard-platform:
    <<: *common-env
    build:
      context: .
      dockerfile: Dockerfile
      args:
        REACT_APP_API_URL: ${REACT_APP_API_URL}
        REACT_APP_PYTHON_API_URL: ${REACT_APP_PYTHON_API_URL}
        REACT_APP_FRONTEND_URL: ${REACT_APP_FRONTEND_URL:-http://localhost:3000}
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT:-3002}:3000"      # Frontend (React)
      - "${NODEJS_API_PORT:-3003}:3001"    # Node.js API
      - "${PYTHON_API_PORT:-8001}:8000"    # Python API
    environment:
      # Database Configuration
      - DATABASE_URL=postgresql://${POSTGRES_USER:-nodeguard}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-nodeguard}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB:-nodeguard}
      - POSTGRES_USER=${POSTGRES_USER:-nodeguard}
      
      # Redis Configuration
      - REDIS_URL=redis://redis:6379
      
      # Elasticsearch Configuration
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=${ELASTICSEARCH_USERNAME:-elastic}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD}
      
      # Kafka Configuration
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      
      # API Keys and External Services
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_BASE_URL=${OPENROUTER_BASE_URL:-https://openrouter.ai/api/v1}
      
      # Security Configuration
      - JWT_SECRET=${JWT_SECRET}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      
      # AI Model Configuration
      - DEFAULT_MODEL=${DEFAULT_MODEL:-anthropic/claude-3.5-sonnet}
      - FALLBACK_MODEL=${FALLBACK_MODEL:-openai/gpt-4o-mini}
      - MAX_TOKENS=${MAX_TOKENS:-4000}
      - TEMPERATURE=${TEMPERATURE:-0.1}
      
      # Application Configuration
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - NODE_ENV=${NODE_ENV:-production}
      - API_PORT=3001
      
      # Frontend Configuration
      - REACT_APP_API_URL=http://localhost:3003
      - REACT_APP_PYTHON_API_URL=http://localhost:8001
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      kafka:
        condition: service_healthy
    volumes:
      - ./models:/app/models:ro
      - ./logs:/app/logs
      - ./data/workflows:/app/data/workflows
    networks:
      - security-network
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 2G
    healthcheck:
      test: ["CMD", "/app/health-check.sh"]
      interval: 30s
      timeout: 30s
      start_period: 60s
      retries: 3

  # Monitoring (disabled for production - uncomment if needed)
  # prometheus:
  #   image: prom/prometheus:v2.48.1
  #   restart: unless-stopped
  #   ports:
  #     - "${PROMETHEUS_PORT:-9090}:9090"
  #   volumes:
  #     - ./infrastructure/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
  #     - prometheus_data:/prometheus
  #   networks:
  #     - security-network

  # grafana:
  #   image: grafana/grafana:10.2.3
  #   restart: unless-stopped  
  #   ports:
  #     - "${GRAFANA_PORT:-3002}:3000"
  #   environment:
  #     - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
  #   volumes:
  #     - grafana_data:/var/lib/grafana
  #   networks:
  #     - security-network

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  elasticsearch_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  kafka_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  security-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16